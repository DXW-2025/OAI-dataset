{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dffd4788-82f5-40c6-9317-0c34814a3b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1/5 =====\n",
      "Fold 1 AUC = 0.6319\n",
      "\n",
      "===== Fold 2/5 =====\n",
      "Fold 2 AUC = 0.7637\n",
      "\n",
      "===== Fold 3/5 =====\n",
      "Fold 3 AUC = 0.8791\n",
      "\n",
      "===== Fold 4/5 =====\n",
      "Fold 4 AUC = 0.8846\n",
      "\n",
      "===== Fold 5/5 =====\n",
      "Fold 5 AUC = 0.6090\n",
      "\n",
      "===== CV 结果 =====\n",
      "5 折 AUC : [0.6319 0.7637 0.8791 0.8846 0.609 ]\n",
      "Mean AUC : 0.7536630036630036\n",
      "Std  AUC : 0.11726761689176682\n",
      "OOF 概率已保存： C:\\Users\\DXW\\Desktop\\半月板部分切除术\\OAI test\\test 3\\XGBoost_OOF_prob.xlsx\n",
      "\n",
      "===== SHAP 解释（5-fold mean ± std） =====\n",
      "SHAP 结果已生成（5 折平均 ± 标准差）：\n",
      "  C:\\Users\\DXW\\Desktop\\半月板部分切除术\\OAI test\\test 3\\SHAP_summary.png\n",
      "  C:\\Users\\DXW\\Desktop\\半月板部分切除术\\OAI test\\test 3\\SHAP_bar.png\n",
      "  C:\\Users\\DXW\\Desktop\\半月板部分切除术\\OAI test\\test 3\\SHAP_force.html\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "XGBoost + CV + SHAP  完整模板\n",
    "行号一一对应，X 仅缺值已补，y 为 WOMKP 0/1\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ========= 1. 路径设置 =========\n",
    "data_dir = pathlib.Path(r\"C:\\Users\\DXW\\Desktop\\半月板部分切除术\\OAI test\\test 3\")\n",
    "x_file   = data_dir / 'pred.xlsx'   # 已补缺失\n",
    "y_file   = data_dir / 'outcome.xlsx'  # 含 WOMKP 0/1\n",
    "oof_file = data_dir / 'XGBoost_OOF_prob.xlsx'\n",
    "shap_summary_path = data_dir / 'SHAP_summary.png'\n",
    "shap_bar_path     = data_dir / 'SHAP_bar.png'\n",
    "shap_force_path   = data_dir / 'SHAP_force.html'\n",
    "\n",
    "# ========= 2. 读数据 =========\n",
    "X_df = pd.read_excel(x_file, sheet_name=\"pred\").drop(columns=['MONTHS','ID', 'side'], errors='ignore')\n",
    "y_df = pd.read_excel(y_file)[['Final']].values.ravel()\n",
    "\n",
    "# ========= 3. 把列分成 3 类 =========\n",
    "# 0/1 列\n",
    "bin_like = [c for c in X_df.columns if X_df[c].dropna().isin([0,1]).all()]\n",
    "# 连续变量：数值型且非 0/1\n",
    "continuous_cols = [\n",
    "    c for c in X_df.select_dtypes(include=['int64','float64']).columns\n",
    "    if c not in bin_like\n",
    "]\n",
    "# 定序变量：如果你知道列名，直接写列表；不知道就默认空\n",
    "ordinal_cols = []          # 例：['KL_grade', 'pain_scale']\n",
    "# 字符串类别：你说过没有，留空\n",
    "string_cols = []\n",
    "\n",
    "# 合并 0/1 与定序 → 都不标准化\n",
    "no_scale_cols = bin_like + ordinal_cols\n",
    "\n",
    "scale_pipe   = Pipeline([('scaler', StandardScaler())])\n",
    "passthrough_pipe = Pipeline([('identity', 'passthrough')])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scale', scale_pipe, continuous_cols),\n",
    "        ('passthrough', passthrough_pipe, no_scale_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# ========= 5. XGBoost 参数 =========\n",
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# ========= 6. 交叉验证 =========\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "auc_scores = []\n",
    "oof_prob = np.zeros(len(X_df))\n",
    "trained_models, val_indices = [], []\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(cv.split(X_df, y_df)):\n",
    "    print(f'\\n===== Fold {fold+1}/5 =====')\n",
    "    X_train_df, X_val_df = X_df.iloc[tr_idx], X_df.iloc[val_idx]\n",
    "    y_train, y_val = y_df[tr_idx], y_df[val_idx]\n",
    "\n",
    "    # 预处理\n",
    "    X_train = preprocessor.fit_transform(X_train_df)\n",
    "    X_val   = preprocessor.transform(X_val_df)\n",
    "\n",
    "    # 训练\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval   = xgb.DMatrix(X_val, label=y_val)\n",
    "    model = xgb.train(\n",
    "        params=xgb_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=200,\n",
    "        evals=[(dtrain, 'train'), (dval, 'eval')],\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    # 预测\n",
    "    val_prob = model.predict(dval)\n",
    "    oof_prob[val_idx] = val_prob\n",
    "    auc = roc_auc_score(y_val, val_prob)\n",
    "    auc_scores.append(auc)\n",
    "    print(f'Fold {fold+1} AUC = {auc:.4f}')\n",
    "\n",
    "    # 存模型和验证索引（SHAP 用）\n",
    "    trained_models.append(model)\n",
    "    val_indices.append(val_idx)\n",
    "\n",
    "# ========= 7. CV 结果 =========\n",
    "print('\\n===== CV 结果 =====')\n",
    "print('5 折 AUC :', np.round(auc_scores, 4))\n",
    "print('Mean AUC :', np.mean(auc_scores))\n",
    "print('Std  AUC :', np.std(auc_scores))\n",
    "\n",
    "# ========= 8. 保存 OOF 概率 =========\n",
    "pd.DataFrame({'OOF_prob': oof_prob, 'label': y_df}).to_excel(oof_file, index=False)\n",
    "print('OOF 概率已保存：', oof_file)\n",
    "\n",
    "# ========= 9. SHAP 解释（逐折算 → 折间平均 ± 标准差） =========\n",
    "print('\\n===== SHAP 解释（5-fold mean ± std） =====')\n",
    "\n",
    "fold_imp = []   # 每折的 mean(|SHAP|)\n",
    "for fold, (model, v_idx) in enumerate(zip(trained_models, val_indices)):\n",
    "    X_val = preprocessor.transform(X_df.iloc[v_idx])\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_val = explainer.shap_values(X_val)        # (n_val_samples, n_features)\n",
    "    fold_imp.append(np.abs(shap_val).mean(axis=0)) # 该折平均绝对值\n",
    "\n",
    "# 折间统计\n",
    "mean_imp = np.mean(fold_imp, axis=0)   # (n_features,)\n",
    "std_imp  = np.std(fold_imp, axis=0)\n",
    "feat_names = preprocessor.get_feature_names_out()\n",
    "shap_df = (pd.DataFrame({'mean': mean_imp, 'std': std_imp}, index=feat_names)\n",
    "             .sort_values('mean', ascending=False))\n",
    "\n",
    "# 画 top30 带误差条\n",
    "top30 = shap_df.head(30)\n",
    "plt.ioff()\n",
    "plt.figure(figsize=(6, 8))\n",
    "y_pos = np.arange(len(top30))\n",
    "plt.barh(y_pos, top30['mean'], xerr=top30['std'], capsize=3,\n",
    "         color='steelblue', alpha=0.8)\n",
    "plt.yticks(y_pos, top30.index)\n",
    "plt.xlabel('mean(|SHAP|) across 5 folds')\n",
    "plt.title('SHAP importance — 5-fold mean ± std')\n",
    "plt.tight_layout()\n",
    "plt.savefig(shap_bar_path, dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# beeswarm 图：把 5 折验证集拼起来后用第 1 折模型画一次即可\n",
    "X_val_concat = np.vstack([preprocessor.transform(X_df.iloc[v_idx])\n",
    "                          for v_idx in val_indices])\n",
    "explainer0 = shap.TreeExplainer(trained_models[0])\n",
    "shap_values_concat = explainer0.shap_values(X_val_concat)\n",
    "shap.summary_plot(shap_values_concat, X_val_concat,\n",
    "                  feature_names=feat_names, show=False)\n",
    "plt.savefig(shap_summary_path, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 个体 force plot（合并后第 0 条样本）\n",
    "html_force = shap.force_plot(explainer0.expected_value,\n",
    "                             shap_values_concat[0, :],\n",
    "                             X_val_concat[0, :],\n",
    "                             feature_names=feat_names)\n",
    "shap.save_html(str(shap_force_path), html_force)\n",
    "\n",
    "print('SHAP 结果已生成（5 折平均 ± 标准差）：')\n",
    "print(' ', shap_summary_path)\n",
    "print(' ', shap_bar_path)\n",
    "print(' ', shap_force_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9354be25-13d6-40c1-b8b8-12398c370450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dicom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
