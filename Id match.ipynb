{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e02ee9f-be27-4470-81f7-77a85c11e9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "程序开始执行\n",
      "==================================================\n",
      "开始整合源数据，共 4796 行...\n",
      "整合进度: 1/4796 (0.0%)\n",
      "整合进度: 1001/4796 (20.9%)\n",
      "整合进度: 2001/4796 (41.7%)\n",
      "整合进度: 3001/4796 (62.6%)\n",
      "整合进度: 4001/4796 (83.4%)\n",
      "整合完成，共 4796 个唯一ID\n",
      "\n",
      "匹配到 68 个ID，共 68 行待写入\n",
      "写入进度: 68/68 (100.0%) - 已用: 0.0s, 剩余: 0.0s\n",
      "\n",
      "正在保存...\n",
      "保存完成！总耗时 15.2秒\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import time\n",
    "\n",
    "# ---------- 基础函数 ----------\n",
    "def load_excel(file_path, sheet_name=0):\n",
    "    \"\"\"读入文件：默认第1个sheet，无需指定\"\"\"\n",
    "    return pd.read_excel(file_path, sheet_name=sheet_name, dtype=str)\n",
    "\n",
    "def write_fields_to_row(ws, row_num, data, field_mapping):\n",
    "    for field, col in field_mapping.items():\n",
    "        if field in data:\n",
    "            ws[f\"{col}{row_num}\"] = data[field]\n",
    "\n",
    "def consolidate_source_data(df, fields_to_consolidate):\n",
    "    \"\"\"\n",
    "    按 ID 聚合指定字段；如果某字段在源表里根本不存在，则给它留空字符串，不报错。\n",
    "    \"\"\"\n",
    "    consolidated = {}\n",
    "    total = len(df)\n",
    "    # 先拿到源表真实列名（统一大写，避免大小写问题）\n",
    "    real_cols = {c.upper() for c in df.columns}\n",
    "\n",
    "    print(f\"开始整合源数据，共 {total} 行...\")\n",
    "    for idx, row in df.iterrows():\n",
    "        name = str(row['ID']).strip().upper() if pd.notna(row['ID']) else None\n",
    "        if not name:\n",
    "            continue\n",
    "\n",
    "        # 首次遇到该 ID\n",
    "        consolidated.setdefault(name, {f: set() for f in fields_to_consolidate})\n",
    "\n",
    "        # 只处理“源表真正存在”的字段\n",
    "        for f in fields_to_consolidate:\n",
    "            if f.upper() not in real_cols:   # 源表没有这一列，直接跳过\n",
    "                continue\n",
    "            val = row.get(f)                # 用 get 防止 KeyError\n",
    "            if pd.notna(val) and str(val).strip():\n",
    "                consolidated[name][f].add(str(val).strip())\n",
    "\n",
    "        # 进度条\n",
    "        if idx % 1000 == 0:\n",
    "            print(f\"整合进度: {idx+1}/{total} ({(idx+1)/total*100:.1f}%)\")\n",
    "\n",
    "    # 集合 → 字符串\n",
    "    for name, data in consolidated.items():\n",
    "        for f in fields_to_consolidate:\n",
    "            consolidated[name][f] = \"; \".join(data[f]) if data[f] else \"\"\n",
    "\n",
    "    print(f\"整合完成，共 {len(consolidated)} 个唯一ID\")\n",
    "    return consolidated\n",
    "\n",
    "def print_progress(current, total, start_time, operation=\"处理\"):\n",
    "    elapsed = time.time() - start_time\n",
    "    progress = (current / total) * 100\n",
    "    remaining = elapsed * total / current - elapsed if current else 0\n",
    "    print(f\"{operation}进度: {current}/{total} ({progress:.1f}%) - 已用: {elapsed:.1f}s, 剩余: {remaining:.1f}s\")\n",
    "\n",
    "# ---------- 字段清单（V00 基线，按用户给定顺序） ----------\n",
    "version='V99'\n",
    "field_list = [\n",
    "    f\"{version}EDDVSPR\",\n",
    "    f\"{version}ELKVSPR\",\n",
    "    f\"{version}ERKVSPR\"\n",
    "]\n",
    "#field_list=[\"V99ELKVSRP\",\"V99ERKVSRP\",\"V99EDDVSPR\"]\n",
    "def col_letter(n):\n",
    "    letter = \"\"\n",
    "    while n:\n",
    "        n, rem = divmod(n - 1, 26)\n",
    "        letter = chr(65 + rem) + letter\n",
    "    return letter\n",
    "\n",
    "\n",
    "field_mapping = {f.upper(): col_letter(i + 4) for i, f in enumerate(field_list)}\n",
    "fields_to_consolidate = list(field_mapping.keys())\n",
    "\n",
    "\n",
    "# ---------- 路径 ----------\n",
    "src_file = r\"C:\\Users\\DXW\\OAI data\\OAIdatabase\\General\\Outcomes99.xlsx\"\n",
    "tgt_file = r\"C:\\Users\\DXW\\Desktop\\半月板手术_信息.xlsx\"\n",
    "tgt_sheet = '12m'   # ← 指定目标 sheet 名称\n",
    "\n",
    "# ---------- 主流程 ----------\n",
    "start_time = time.time()\n",
    "print(\"=\" * 50)\n",
    "print(\"程序开始执行\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 读源（不指定 sheet，默认第 1 个）\n",
    "df = load_excel(src_file)\n",
    "df.columns = df.columns.str.strip().str.upper()  \n",
    "consolidated_data = consolidate_source_data(df, fields_to_consolidate)\n",
    "\n",
    "# 读目标（指定 sheet）\n",
    "wb = load_workbook(tgt_file)\n",
    "ws = wb[tgt_sheet]\n",
    "\n",
    "\n",
    "# 构建 ID→行号映射（不区分大小写）\n",
    "acc_number_to_rows = {}\n",
    "for row_num, row in enumerate(ws.iter_rows(min_row=2, min_col=1, max_col=2), start=2):\n",
    "    acc = str(row[0].value).strip().upper() if row[0].value is not None else None\n",
    "    if acc and acc != 'NONE':\n",
    "        acc_number_to_rows.setdefault(acc, []).append(row_num)\n",
    "\n",
    "matched_names = [n for n in consolidated_data if n in acc_number_to_rows]\n",
    "total_matched_rows = sum(len(acc_number_to_rows[n]) for n in matched_names)\n",
    "print(f\"\\n匹配到 {len(matched_names)} 个ID，共 {total_matched_rows} 行待写入\")\n",
    "\n",
    "# 写入\n",
    "write_start = time.time()\n",
    "i = 0\n",
    "for name_idx, (name, data) in enumerate(consolidated_data.items()):\n",
    "    if name in acc_number_to_rows:\n",
    "        for row_num in acc_number_to_rows[name]:\n",
    "            i += 1\n",
    "            write_fields_to_row(ws, row_num, data, field_mapping)\n",
    "            if i % 100 == 0:\n",
    "                print_progress(i, total_matched_rows, write_start, \"写入\")\n",
    "\n",
    "if i > 0:\n",
    "    print_progress(i, total_matched_rows, write_start, \"写入\")\n",
    "\n",
    "# 保存\n",
    "print(\"\\n正在保存...\")\n",
    "wb.save(tgt_file)\n",
    "print(f\"保存完成！总耗时 {time.time() - start_time:.1f}秒\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d976d5ed-3ddc-4017-b1b7-67fda7849d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "程序开始执行\n",
      "==================================================\n",
      "开始整合源数据，共 4796 行，使用版本: ['V00', 'P01']...\n",
      "整合进度: 1/4796 (0.0%)\n",
      "整合进度: 1001/4796 (20.9%)\n",
      "整合进度: 2001/4796 (41.7%)\n",
      "整合进度: 3001/4796 (62.6%)\n",
      "整合进度: 4001/4796 (83.4%)\n",
      "整合完成，共 4796 个唯一ID\n",
      "\n",
      "匹配到 68 个ID，共 68 行待写入\n",
      "写入进度: 68/68 (100.0%) - 已用: 0.2s, 剩余: 0.0s\n",
      "\n",
      "正在保存...\n",
      "保存完成！总耗时 203.7秒\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import time\n",
    "\n",
    "# ---------- 基础函数 ----------\n",
    "def load_excel(file_path, sheet_name=0):\n",
    "    \"\"\"读入文件：默认第1个sheet，无需指定\"\"\"\n",
    "    return pd.read_excel(file_path, sheet_name=sheet_name, dtype=str)\n",
    "\n",
    "def write_fields_to_row(ws, row_num, data, field_mapping):\n",
    "    for field, col in field_mapping.items():\n",
    "        if field in data:\n",
    "            ws[f\"{col}{row_num}\"] = data[field]\n",
    "\n",
    "def consolidate_source_data(df, fields_to_consolidate, versions=[\"V00\", \"P01\"]):\n",
    "    \"\"\"\n",
    "    按 ID 聚合指定字段；尝试多个版本匹配字段\n",
    "    \"\"\"\n",
    "    consolidated = {}\n",
    "    total = len(df)\n",
    "    # 先拿到源表真实列名（统一大写，避免大小写问题）\n",
    "    real_cols = {c.upper() for c in df.columns}\n",
    "    \n",
    "    # 提取基础字段名（去掉版本前缀）\n",
    "    base_fields = []\n",
    "    field_version_map = {}  # 基础字段名 -> 完整字段名（带V00前缀）\n",
    "    \n",
    "    for full_field in fields_to_consolidate:\n",
    "        # 找到基础字段名（去掉前3个字符的版本前缀）\n",
    "        for version in versions:\n",
    "            if full_field.startswith(version):\n",
    "                base_field = full_field[len(version):]\n",
    "                base_fields.append(base_field)\n",
    "                field_version_map[base_field] = full_field\n",
    "                break\n",
    "    \n",
    "    print(f\"开始整合源数据，共 {total} 行，使用版本: {versions}...\")\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        name = str(row['ID']).strip().upper() if pd.notna(row['ID']) else None\n",
    "        if not name:\n",
    "            continue\n",
    "\n",
    "        # 首次遇到该 ID\n",
    "        if name not in consolidated:\n",
    "            consolidated[name] = {field_version_map[bf]: set() for bf in base_fields}\n",
    "\n",
    "        # 处理每个基础字段\n",
    "        for base_field in base_fields:\n",
    "            full_field = field_version_map[base_field]\n",
    "            \n",
    "            # 按版本顺序尝试匹配\n",
    "            for version in versions:\n",
    "                field_to_check = version + base_field\n",
    "                if field_to_check.upper() in real_cols:  # 检查源表是否有这个字段\n",
    "                    val = row.get(field_to_check)  # 用 get 防止 KeyError\n",
    "                    if pd.notna(val) and str(val).strip():\n",
    "                        consolidated[name][full_field].add(str(val).strip())\n",
    "                        break  # 找到值就跳出版本循环\n",
    "\n",
    "        # 进度条\n",
    "        if idx % 1000 == 0:\n",
    "            print(f\"整合进度: {idx+1}/{total} ({(idx+1)/total*100:.1f}%)\")\n",
    "\n",
    "    # 集合 → 字符串\n",
    "    for name, data in consolidated.items():\n",
    "        for full_field in data:\n",
    "            consolidated[name][full_field] = \"; \".join(data[full_field]) if data[full_field] else \"\"\n",
    "\n",
    "    print(f\"整合完成，共 {len(consolidated)} 个唯一ID\")\n",
    "    return consolidated\n",
    "\n",
    "def print_progress(current, total, start_time, operation=\"处理\"):\n",
    "    elapsed = time.time() - start_time\n",
    "    progress = (current / total) * 100\n",
    "    remaining = elapsed * total / current - elapsed if current else 0\n",
    "    print(f\"{operation}进度: {current}/{total} ({progress:.1f}%) - 已用: {elapsed:.1f}s, 剩余: {remaining:.1f}s\")\n",
    "\n",
    "# ---------- 字段清单（使用V00作为主版本，但会尝试P01） ----------\n",
    "version='V00'\n",
    "versions_to_try = [\"V00\", \"P01\"]  # 定义要尝试的版本顺序\n",
    "\n",
    "field_list = [\n",
    "    f\"{version}SF1\",\n",
    "    f\"{version}SF2\",\n",
    "    f\"{version}SF3\",\n",
    "    f\"{version}SF4\",\n",
    "    f\"{version}SF5\",\n",
    "    f\"{version}SF6\",\n",
    "    f\"{version}SF7\",\n",
    "    f\"{version}SF8\",\n",
    "    f\"{version}SF9\",\n",
    "    f\"{version}SF10\",\n",
    "    f\"{version}SF11\",\n",
    "    f\"{version}SF12\",\n",
    "    f\"{version}KPNR12\",\n",
    "    f\"{version}KPNR12M\",\n",
    "    f\"{version}KPNL12\",\n",
    "    f\"{version}KPNL12M\",\n",
    "    f\"{version}KPACT30\",\n",
    "    f\"{version}WPRKN1\",\n",
    "    f\"{version}WPRKN2\",\n",
    "    f\"{version}WPRKN3\",\n",
    "    f\"{version}WPRKN4\",\n",
    "    f\"{version}WPRKN5\",\n",
    "    f\"{version}KPRKN1\",\n",
    "    f\"{version}KPRKN2\",\n",
    "    f\"{version}KPRKN3\",\n",
    "    f\"{version}P7RKFR\",\n",
    "    f\"{version}WSRKN1\",\n",
    "    f\"{version}WSRKN2\",\n",
    "    f\"{version}KSXRKN1\",\n",
    "    f\"{version}KSXRKN2\",\n",
    "    f\"{version}KSXRKN3\",\n",
    "    f\"{version}KSXRKN4\",\n",
    "    f\"{version}KSXRKN5\",\n",
    "    f\"{version}DIRKN1\",\n",
    "    f\"{version}DIRKN2\",\n",
    "    f\"{version}DIRKN3\",\n",
    "    f\"{version}DIRKN4\",\n",
    "    f\"{version}DIRKN5\",\n",
    "    f\"{version}DIRKN6\",\n",
    "    f\"{version}DIRKN7\",\n",
    "    f\"{version}DIRKN8\",\n",
    "    f\"{version}DIRKN9\",\n",
    "    f\"{version}DIRKN10\",\n",
    "    f\"{version}DIRKN11\",\n",
    "    f\"{version}DIRKN12\",\n",
    "    f\"{version}DIRKN13\",\n",
    "    f\"{version}DIRKN14\",\n",
    "    f\"{version}DIRKN15\",\n",
    "    f\"{version}DIRKN16\",\n",
    "    f\"{version}DIRKN17\",\n",
    "    f\"{version}WPLKN1\",\n",
    "    f\"{version}WPLKN2\",\n",
    "    f\"{version}WPLKN3\",\n",
    "    f\"{version}WPLKN4\",\n",
    "    f\"{version}WPLKN5\",\n",
    "    f\"{version}KPLKN1\",\n",
    "    f\"{version}KPLKN2\",\n",
    "    f\"{version}KPLKN3\",\n",
    "    f\"{version}P7LKFR\",\n",
    "    f\"{version}WSLKN1\",\n",
    "    f\"{version}WSLKN2\",\n",
    "    f\"{version}KSXLKN1\",\n",
    "    f\"{version}KSXLKN2\",\n",
    "    f\"{version}KSXLKN3\",\n",
    "    f\"{version}KSXLKN4\",\n",
    "    f\"{version}KSXLKN5\",\n",
    "    f\"{version}DILKN1\",\n",
    "    f\"{version}DILKN2\",\n",
    "    f\"{version}DILKN3\",\n",
    "    f\"{version}DILKN4\",\n",
    "    f\"{version}DILKN5\",\n",
    "    f\"{version}DILKN6\",\n",
    "    f\"{version}DILKN7\",\n",
    "    f\"{version}DILKN8\",\n",
    "    f\"{version}DILKN9\",\n",
    "    f\"{version}DILKN10\",\n",
    "    f\"{version}DILKN11\",\n",
    "    f\"{version}DILKN12\",\n",
    "    f\"{version}DILKN13\",\n",
    "    f\"{version}DILKN14\",\n",
    "    f\"{version}DILKN15\",\n",
    "    f\"{version}DILKN16\",\n",
    "    f\"{version}DILKN17\",\n",
    "    f\"{version}KOOSFX1\",\n",
    "    f\"{version}KOOSFX2\",\n",
    "    f\"{version}KOOSFX3\",\n",
    "    f\"{version}KOOSFX4\",\n",
    "    f\"{version}KOOSFX5\",\n",
    "    f\"{version}KQOL1\",\n",
    "    f\"{version}KQOL2\",\n",
    "    f\"{version}KQOL3\",\n",
    "    f\"{version}KQOL4\",\n",
    "    f\"{version}KGLRS\",\n",
    "    f\"{version}HPNR12\",\n",
    "    f\"{version}HPNRIL\",\n",
    "    f\"{version}HPNROL\",\n",
    "    f\"{version}HPNRFL\",\n",
    "    f\"{version}HPNRB\",\n",
    "    f\"{version}HPNRLB\",\n",
    "    f\"{version}HPNRDK\",\n",
    "    f\"{version}HPNL12\",\n",
    "    f\"{version}HPNLIL\",\n",
    "    f\"{version}HPNLOL\",\n",
    "    f\"{version}HPNLFL\",\n",
    "    f\"{version}HPNLB\",\n",
    "    f\"{version}HPNLLB\",\n",
    "    f\"{version}HPNLDK\",\n",
    "    f\"{version}BP30\",\n",
    "    f\"{version}BP30OFT\",\n",
    "    f\"{version}BPBAD\",\n",
    "    f\"{version}BPUB\",\n",
    "    f\"{version}BPMB\",\n",
    "    f\"{version}BPLB\",\n",
    "    f\"{version}BPB\",\n",
    "    f\"{version}BPDK\",\n",
    "    f\"{version}OJPNRS\",\n",
    "    f\"{version}OJPNLS\",\n",
    "    f\"{version}OJPNRE\",\n",
    "    f\"{version}OJPNLE\",\n",
    "    f\"{version}OJPNRW\",\n",
    "    f\"{version}OJPNLW\",\n",
    "    f\"{version}OJPNRH\",\n",
    "    f\"{version}OJPNLH\",\n",
    "    f\"{version}OJPNRA\",\n",
    "    f\"{version}OJPNLA\",\n",
    "    f\"{version}OJPNRF\",\n",
    "    f\"{version}OJPNLF\",\n",
    "    f\"{version}OJPNNK\",\n",
    "    f\"{version}OJPNNO\",\n",
    "    f\"{version}WOMTSL\",\n",
    "    f\"{version}LKSX\",\n",
    "    f\"{version}KPA30CV\",\n",
    "    f\"{version}KPL12CV\",\n",
    "    f\"{version}BPBEDCV\",\n",
    "    f\"{version}BPTOT\",\n",
    "    f\"{version}RKP30CV\",\n",
    "    f\"{version}KPACDCV\",\n",
    "    f\"{version}WOMSTFL\",\n",
    "    f\"{version}PMLKRCV\",\n",
    "    f\"{version}KOOSYML\",\n",
    "    f\"{version}HPR12CV\",\n",
    "    f\"{version}KOOSKPL\",\n",
    "    f\"{version}KOOSFSR\",\n",
    "    f\"{version}P7LKRCV\",\n",
    "    f\"{version}BPDAYCV\",\n",
    "    f\"{version}RKSX\",\n",
    "    f\"{version}WOMSTFR\",\n",
    "    f\"{version}KOOSYMR\",\n",
    "    f\"{version}KOOSKPR\",\n",
    "    f\"{version}HSMSS\",\n",
    "    f\"{version}WOMKPR\",\n",
    "    f\"{version}KOOSQOL\",\n",
    "    f\"{version}KPR30CV\",\n",
    "    f\"{version}WOMADLR\",\n",
    "    f\"{version}HPL12CV\",\n",
    "    f\"{version}KPR12CV\",\n",
    "    f\"{version}WOMTSR\",\n",
    "    f\"{version}KPACTCV\",\n",
    "    f\"{version}WOMKPL\",\n",
    "    f\"{version}LKP30CV\",\n",
    "    f\"{version}PMRKRCV\",\n",
    "    f\"{version}HSPSS\",\n",
    "    f\"{version}WOMADLL\",\n",
    "    f\"{version}P7RKRCV\",\n",
    "    f\"{version}KPL30CV\",\n",
    "    f\"{version}BPACTCV\",\n",
    "    f\"{version}KSX\",\n",
    "    f\"{version}BONFX\",\n",
    "    f\"{version}FALL\",\n",
    "    f\"{version}CESD1\",\n",
    "    f\"{version}CESD2\",\n",
    "    f\"{version}CESD3\",\n",
    "    f\"{version}CESD4\",\n",
    "    f\"{version}CESD5\",\n",
    "    f\"{version}CESD6\",\n",
    "    f\"{version}CESD7\",\n",
    "    f\"{version}CESD8\",\n",
    "    f\"{version}CESD9\",\n",
    "    f\"{version}CESD10\",\n",
    "    f\"{version}CESD11\",\n",
    "    f\"{version}CESD12\",\n",
    "    f\"{version}CESD13\",\n",
    "    f\"{version}CESD14\",\n",
    "    f\"{version}CESD15\",\n",
    "    f\"{version}CESD16\",\n",
    "    f\"{version}CESD17\",\n",
    "    f\"{version}CESD18\",\n",
    "    f\"{version}CESD19\",\n",
    "    f\"{version}CESD20\",\n",
    "    f\"{version}ARTH12\",\n",
    "    f\"{version}ARTDOC\",\n",
    "    f\"{version}RAIA12\",\n",
    "    f\"{version}KPMED\",\n",
    "    f\"{version}INJR12\",\n",
    "    f\"{version}INJL12\",\n",
    "    f\"{version}HRS12\",\n",
    "    f\"{version}TYLEN\",\n",
    "    f\"{version}NSAIDS\",\n",
    "    f\"{version}NSAIDRX\",\n",
    "    f\"{version}COXIBS\",\n",
    "    f\"{version}NARCOT\",\n",
    "    f\"{version}SAME\",\n",
    "    f\"{version}MSM\",\n",
    "    f\"{version}DOXYCYC\",\n",
    "    f\"{version}PNMEDT\",\n",
    "    f\"{version}CHON\",\n",
    "    f\"{version}GLUC\",\n",
    "    f\"{version}KNINJ\",\n",
    "    f\"{version}HYALKN\",\n",
    "    f\"{version}STERKN\",\n",
    "    f\"{version}TEST\",\n",
    "    f\"{version}TESTUSE\",\n",
    "    f\"{version}ESTR\",\n",
    "    f\"{version}ESTRUSE\",\n",
    "    f\"{version}GNRH\",\n",
    "    f\"{version}GNRHUSE\",\n",
    "    f\"{version}PTH\",\n",
    "    f\"{version}PTHUSE\",\n",
    "    f\"{version}BISPHOS\",\n",
    "    f\"{version}BISPYRS\",\n",
    "    f\"{version}BISPUSE\",\n",
    "    f\"{version}RX30\",\n",
    "    f\"{version}RX30NUM\",\n",
    "    f\"{version}RXFLUOR\",\n",
    "    f\"{version}RXCLCTN\",\n",
    "    f\"{version}RXBISPH\",\n",
    "    f\"{version}STRINJR\",\n",
    "    f\"{version}HYAINJL\",\n",
    "    f\"{version}STINJCV\",\n",
    "    f\"{version}RXCLCXB\",\n",
    "    f\"{version}CESD\",\n",
    "    f\"{version}OTA12CV\",\n",
    "    f\"{version}OAH12CV\",\n",
    "    f\"{version}RXIHYAL\",\n",
    "    f\"{version}HYAINJR\",\n",
    "    f\"{version}RXNTRAT\",\n",
    "    f\"{version}OAO12CV\",\n",
    "    f\"{version}STRINJL\",\n",
    "    f\"{version}RXASPRN\",\n",
    "    f\"{version}RXCOX2\",\n",
    "    f\"{version}OAF12CV\",\n",
    "    f\"{version}HYINJCV\",\n",
    "    f\"{version}GLCFQCV\",\n",
    "    f\"{version}RXVLCXB\",\n",
    "    f\"{version}CHNFQCV\",\n",
    "    f\"{version}FALLCV\",\n",
    "    f\"{version}OAD12CV\",\n",
    "    f\"{version}RXISTRD\",\n",
    "    f\"{version}RXMSM\",\n",
    "    f\"{version}RXNARC\",\n",
    "    f\"{version}RXRFCXB\",\n",
    "    f\"{version}RXCHOND\",\n",
    "    f\"{version}RXACTM\",\n",
    "    f\"{version}RASTAFU\",\n",
    "    f\"{version}RXGLCSM\",\n",
    "    f\"{version}KPMEDCV\",\n",
    "    f\"{version}OAB12CV\",\n",
    "    f\"{version}BISPTYP\",\n",
    "    f\"{version}ARTDRCV\",\n",
    "    f\"{version}RXANALG\",\n",
    "    f\"{version}RXSALIC\",\n",
    "    f\"{version}RXNSAID\",\n",
    "    f\"{version}RXTPRTD\",\n",
    "    f\"{version}RXSAME\",\n",
    "    f\"{version}RXRALOX\",\n",
    "    f\"{version}GT12CV\",\n",
    "    f\"{version}RXOSTRD\",\n",
    "    f\"{version}RXVIT_D\",\n",
    "    f\"{version}RXOTHAN\",\n",
    "    f\"{version}P30VT1\",\n",
    "    f\"{version}P30VT2\",\n",
    "    f\"{version}P30VT3\",\n",
    "    f\"{version}P30VT4\",\n",
    "    f\"{version}P30VT5\",\n",
    "    f\"{version}P30VT6\",\n",
    "    f\"{version}P30VT7\",\n",
    "    f\"{version}P30VT8\",\n",
    "    f\"{version}P30VT9\",\n",
    "    f\"{version}P30VT10\",\n",
    "    f\"{version}P30VITC\",\n",
    "    f\"{version}VITCAMT\",\n",
    "    f\"{version}P30VITD\",\n",
    "    f\"{version}VITDAMT\",\n",
    "    f\"{version}P30VITE\",\n",
    "    f\"{version}VITEAMT\",\n",
    "    f\"{version}BPSYS\",\n",
    "    f\"{version}BPDIAS\",\n",
    "    f\"{version}CSTSGL\",\n",
    "    f\"{version}CSTREP1\",\n",
    "    f\"{version}CSTIME1\",\n",
    "    f\"{version}CSTREP2\",\n",
    "    f\"{version}CSTIME2\",\n",
    "    f\"{version}KPRK20B\",\n",
    "    f\"{version}KPLK20B\",\n",
    "    f\"{version}WLK20T1\",\n",
    "    f\"{version}STEPST1\",\n",
    "    f\"{version}TIMET1\",\n",
    "    f\"{version}WLK20T2\",\n",
    "    f\"{version}STEPST2\",\n",
    "    f\"{version}TIMET2\",\n",
    "    f\"{version}WLKAID\",\n",
    "    f\"{version}KPRK20D\",\n",
    "    f\"{version}KPLK20D\",\n",
    "    f\"{version}20MPACE\",\n",
    "    f\"{version}WEIGHT\",\n",
    "    f\"{version}BMI\",\n",
    "    f\"{version}HLTHCAR\",\n",
    "    f\"{version}HLTHCOV\",\n",
    "    f\"{version}MEDINS\",\n",
    "    f\"{version}PA230\",\n",
    "    f\"{version}PA330\",\n",
    "    f\"{version}PA530\",\n",
    "    f\"{version}PA430\",\n",
    "    f\"{version}PA130\",\n",
    "    f\"{version}PASE1\",\n",
    "    f\"{version}PASE1HR\",\n",
    "    f\"{version}PASE2\",\n",
    "    f\"{version}PASE2HR\",\n",
    "    f\"{version}PASE3\",\n",
    "    f\"{version}PASE3HR\",\n",
    "    f\"{version}PASE4\",\n",
    "    f\"{version}PASE4HR\",\n",
    "    f\"{version}PASE5\",\n",
    "    f\"{version}PASE5HR\",\n",
    "    f\"{version}PASE6\",\n",
    "    f\"{version}PASE6HR\",\n",
    "    f\"{version}HOUACT1\",\n",
    "    f\"{version}HOUACT2\",\n",
    "    f\"{version}HOUACT3\",\n",
    "    f\"{version}HOUACT4\",\n",
    "    f\"{version}HOUACT5\",\n",
    "    f\"{version}HOUACT6\",\n",
    "    f\"{version}WORK7\",\n",
    "    f\"{version}WORKAMT\",\n",
    "    f\"{version}CUREMP\",\n",
    "    f\"{version}WEEKWK\",\n",
    "    f\"{version}HOURWK\",\n",
    "    f\"{version}MISSWK\",\n",
    "    f\"{version}PA530CV\",\n",
    "    f\"{version}PA330CV\",\n",
    "    f\"{version}PA130CV\",\n",
    "    f\"{version}CEMPLOY\",\n",
    "    f\"{version}PASE\",\n",
    "    f\"{version}AGE\",\n",
    "    f\"{version}PA430CV\",\n",
    "    f\"{version}PA230CV\",\n",
    "    f\"{version}WKHR7CV\"\n",
    "]\n",
    "\n",
    "def col_letter(n):\n",
    "    letter = \"\"\n",
    "    while n:\n",
    "        n, rem = divmod(n - 1, 26)\n",
    "        letter = chr(65 + rem) + letter\n",
    "    return letter\n",
    "\n",
    "# 创建字段映射（使用V00版本的字段名作为输出列）\n",
    "field_mapping = {f.upper(): col_letter(i + 7) for i, f in enumerate(field_list)}\n",
    "fields_to_consolidate = list(field_mapping.keys())\n",
    "\n",
    "# ---------- 路径 ----------\n",
    "src_file = r\"C:\\Users\\DXW\\OAI data\\OAIdatabase\\Allclinical\\Allclinical00.xlsx\"\n",
    "tgt_file = r\"C:\\Users\\DXW\\Desktop\\半月板手术_信息.xlsx\"\n",
    "tgt_sheet = '12m'   # ← 指定目标 sheet 名称\n",
    "\n",
    "# ---------- 主流程 ----------\n",
    "start_time = time.time()\n",
    "print(\"=\" * 50)\n",
    "print(\"程序开始执行\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 读源（不指定 sheet，默认第 1 个）\n",
    "df = load_excel(src_file)\n",
    "df.columns = df.columns.str.strip().str.upper()\n",
    "\n",
    "# 使用多版本整合数据\n",
    "consolidated_data = consolidate_source_data(df, fields_to_consolidate, versions=[\"V00\", \"P01\"])\n",
    "\n",
    "# 读目标（指定 sheet）\n",
    "wb = load_workbook(tgt_file)\n",
    "ws = wb[tgt_sheet]\n",
    "\n",
    "# 构建 ID→行号映射（不区分大小写）\n",
    "acc_number_to_rows = {}\n",
    "for row_num, row in enumerate(ws.iter_rows(min_row=2, min_col=1, max_col=2), start=2):\n",
    "    acc = str(row[0].value).strip().upper() if row[0].value is not None else None\n",
    "    if acc and acc != 'NONE':\n",
    "        acc_number_to_rows.setdefault(acc, []).append(row_num)\n",
    "\n",
    "matched_names = [n for n in consolidated_data if n in acc_number_to_rows]\n",
    "total_matched_rows = sum(len(acc_number_to_rows[n]) for n in matched_names)\n",
    "print(f\"\\n匹配到 {len(matched_names)} 个ID，共 {total_matched_rows} 行待写入\")\n",
    "\n",
    "# 写入\n",
    "write_start = time.time()\n",
    "i = 0\n",
    "for name_idx, (name, data) in enumerate(consolidated_data.items()):\n",
    "    if name in acc_number_to_rows:\n",
    "        for row_num in acc_number_to_rows[name]:\n",
    "            i += 1\n",
    "            write_fields_to_row(ws, row_num, data, field_mapping)\n",
    "            if i % 100 == 0:\n",
    "                print_progress(i, total_matched_rows, write_start, \"写入\")\n",
    "\n",
    "if i > 0:\n",
    "    print_progress(i, total_matched_rows, write_start, \"写入\")\n",
    "\n",
    "# 保存\n",
    "print(\"\\n正在保存...\")\n",
    "wb.save(tgt_file)\n",
    "print(f\"保存完成！总耗时 {time.time() - start_time:.1f}秒\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33e09a0f-bee8-4746-9644-1d8d3309b159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "程序开始执行\n",
      "==================================================\n",
      "开始整合源数据，共 64513 行，使用版本: ['V00']...\n",
      "整合进度: 1/64513 (0.0%)\n",
      "整合进度: 1001/64513 (1.6%)\n",
      "整合进度: 2001/64513 (3.1%)\n",
      "整合进度: 3001/64513 (4.7%)\n",
      "整合进度: 4001/64513 (6.2%)\n",
      "整合进度: 5001/64513 (7.8%)\n",
      "整合进度: 6001/64513 (9.3%)\n",
      "整合进度: 7001/64513 (10.9%)\n",
      "整合进度: 8001/64513 (12.4%)\n",
      "整合进度: 9001/64513 (14.0%)\n",
      "整合进度: 10001/64513 (15.5%)\n",
      "整合进度: 11001/64513 (17.1%)\n",
      "整合进度: 12001/64513 (18.6%)\n",
      "整合进度: 13001/64513 (20.2%)\n",
      "整合进度: 14001/64513 (21.7%)\n",
      "整合进度: 15001/64513 (23.3%)\n",
      "整合进度: 16001/64513 (24.8%)\n",
      "整合进度: 17001/64513 (26.4%)\n",
      "整合进度: 18001/64513 (27.9%)\n",
      "整合进度: 19001/64513 (29.5%)\n",
      "整合进度: 20001/64513 (31.0%)\n",
      "整合进度: 21001/64513 (32.6%)\n",
      "整合进度: 22001/64513 (34.1%)\n",
      "整合进度: 23001/64513 (35.7%)\n",
      "整合进度: 24001/64513 (37.2%)\n",
      "整合进度: 25001/64513 (38.8%)\n",
      "整合进度: 26001/64513 (40.3%)\n",
      "整合进度: 27001/64513 (41.9%)\n",
      "整合进度: 28001/64513 (43.4%)\n",
      "整合进度: 29001/64513 (45.0%)\n",
      "整合进度: 30001/64513 (46.5%)\n",
      "整合进度: 31001/64513 (48.1%)\n",
      "整合进度: 32001/64513 (49.6%)\n",
      "整合进度: 33001/64513 (51.2%)\n",
      "整合进度: 34001/64513 (52.7%)\n",
      "整合进度: 35001/64513 (54.3%)\n",
      "整合进度: 36001/64513 (55.8%)\n",
      "整合进度: 37001/64513 (57.4%)\n",
      "整合进度: 38001/64513 (58.9%)\n",
      "整合进度: 39001/64513 (60.5%)\n",
      "整合进度: 40001/64513 (62.0%)\n",
      "整合进度: 41001/64513 (63.6%)\n",
      "整合进度: 42001/64513 (65.1%)\n",
      "整合进度: 43001/64513 (66.7%)\n",
      "整合进度: 44001/64513 (68.2%)\n",
      "整合进度: 45001/64513 (69.8%)\n",
      "整合进度: 46001/64513 (71.3%)\n",
      "整合进度: 47001/64513 (72.9%)\n",
      "整合进度: 48001/64513 (74.4%)\n",
      "整合进度: 49001/64513 (76.0%)\n",
      "整合进度: 50001/64513 (77.5%)\n",
      "整合进度: 51001/64513 (79.1%)\n",
      "整合进度: 52001/64513 (80.6%)\n",
      "整合进度: 53001/64513 (82.2%)\n",
      "整合进度: 54001/64513 (83.7%)\n",
      "整合进度: 55001/64513 (85.3%)\n",
      "整合进度: 56001/64513 (86.8%)\n",
      "整合进度: 57001/64513 (88.4%)\n",
      "整合进度: 58001/64513 (89.9%)\n",
      "整合进度: 59001/64513 (91.5%)\n",
      "整合进度: 60001/64513 (93.0%)\n",
      "整合进度: 61001/64513 (94.6%)\n",
      "整合进度: 62001/64513 (96.1%)\n",
      "整合进度: 63001/64513 (97.7%)\n",
      "整合进度: 64001/64513 (99.2%)\n",
      "整合完成，共 4791 个唯一ID\n",
      "\n",
      "匹配到 68 个ID，共 73 行待写入\n",
      "写入进度: 73/73 (100.0%) - 已用: 0.0s, 剩余: 0.0s\n",
      "\n",
      "正在保存...\n",
      "保存完成！总耗时 22.3秒\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import time\n",
    "\n",
    "# ---------- 基础函数 ----------\n",
    "def load_excel(file_path, sheet_name=0):\n",
    "    \"\"\"读入文件：默认第1个sheet，无需指定\"\"\"\n",
    "    return pd.read_excel(file_path, sheet_name=sheet_name, dtype=str)\n",
    "\n",
    "def write_fields_to_row(ws, row_num, data, field_mapping):\n",
    "    for field, col in field_mapping.items():\n",
    "        if field in data:\n",
    "            ws[f\"{col}{row_num}\"] = data[field]\n",
    "\n",
    "def consolidate_source_data(df, fields_to_consolidate, versions=[\"V00\", \"P01\"]):\n",
    "    \"\"\"\n",
    "    按 ID 聚合指定字段；尝试多个版本匹配字段\n",
    "    \"\"\"\n",
    "    consolidated = {}\n",
    "    total = len(df)\n",
    "    # 先拿到源表真实列名（统一大写，避免大小写问题）\n",
    "    real_cols = {c.upper() for c in df.columns}\n",
    "    \n",
    "    # 提取基础字段名（去掉版本前缀）\n",
    "    base_fields = []\n",
    "    field_version_map = {}  # 基础字段名 -> 完整字段名（带V00前缀）\n",
    "    \n",
    "    for full_field in fields_to_consolidate:\n",
    "        # 找到基础字段名（去掉前3个字符的版本前缀）\n",
    "        for version in versions:\n",
    "            if full_field.startswith(version):\n",
    "                base_field = full_field[len(version):]\n",
    "                base_fields.append(base_field)\n",
    "                field_version_map[base_field] = full_field\n",
    "                break\n",
    "    \n",
    "    print(f\"开始整合源数据，共 {total} 行，使用版本: {versions}...\")\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        name = str(row['ID']).strip().upper() if pd.notna(row['ID']) else None\n",
    "        if not name:\n",
    "            continue\n",
    "\n",
    "        # 首次遇到该 ID\n",
    "        if name not in consolidated:\n",
    "            consolidated[name] = {field_version_map[bf]: set() for bf in base_fields}\n",
    "\n",
    "        # 处理每个基础字段\n",
    "        for base_field in base_fields:\n",
    "            full_field = field_version_map[base_field]\n",
    "            \n",
    "            # 按版本顺序尝试匹配\n",
    "            for version in versions:\n",
    "                field_to_check = version + base_field\n",
    "                if field_to_check.upper() in real_cols:  # 检查源表是否有这个字段\n",
    "                    val = row.get(field_to_check)  # 用 get 防止 KeyError\n",
    "                    if pd.notna(val) and str(val).strip():\n",
    "                        consolidated[name][full_field].add(str(val).strip())\n",
    "                        break  # 找到值就跳出版本循环\n",
    "\n",
    "        # 进度条\n",
    "        if idx % 1000 == 0:\n",
    "            print(f\"整合进度: {idx+1}/{total} ({(idx+1)/total*100:.1f}%)\")\n",
    "\n",
    "    # 集合 → 字符串\n",
    "    for name, data in consolidated.items():\n",
    "        for full_field in data:\n",
    "            consolidated[name][full_field] = \"; \".join(data[full_field]) if data[full_field] else \"\"\n",
    "\n",
    "    print(f\"整合完成，共 {len(consolidated)} 个唯一ID\")\n",
    "    return consolidated\n",
    "\n",
    "def print_progress(current, total, start_time, operation=\"处理\"):\n",
    "    elapsed = time.time() - start_time\n",
    "    progress = (current / total) * 100\n",
    "    remaining = elapsed * total / current - elapsed if current else 0\n",
    "    print(f\"{operation}进度: {current}/{total} ({progress:.1f}%) - 已用: {elapsed:.1f}s, 剩余: {remaining:.1f}s\")\n",
    "\n",
    "# ---------- 字段清单（使用V00作为主版本，但会尝试P01） ----------\n",
    "\n",
    "versions_to_try = [\"V00\"]  # 定义要尝试的版本顺序\n",
    "\n",
    "field_list = [\n",
    "    f\"{version}MRSIDE\",\n",
    "    f\"{version}MRCOMP\",\n",
    "]\n",
    "\n",
    "def col_letter(n):\n",
    "    letter = \"\"\n",
    "    while n:\n",
    "        n, rem = divmod(n - 1, 26)\n",
    "        letter = chr(65 + rem) + letter\n",
    "    return letter\n",
    "\n",
    "# 创建字段映射（使用V00版本的字段名作为输出列）\n",
    "field_mapping = {f.upper(): col_letter(i + 8) for i, f in enumerate(field_list)}\n",
    "fields_to_consolidate = list(field_mapping.keys())\n",
    "\n",
    "# ---------- 路径 ----------\n",
    "src_file = r\"C:\\Users\\DXW\\Desktop\\新建 Microsoft Excel 工作表.xlsx\"\n",
    "tgt_file = r\"C:\\Users\\DXW\\Desktop\\半月板手术_信息.xlsx\"\n",
    "tgt_sheet = '12m'   # ← 指定目标 sheet 名称\n",
    "\n",
    "# ---------- 主流程 ----------\n",
    "start_time = time.time()\n",
    "print(\"=\" * 50)\n",
    "print(\"程序开始执行\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 读源（不指定 sheet，默认第 1 个）\n",
    "df = load_excel(src_file)\n",
    "df.columns = df.columns.str.strip().str.upper()\n",
    "\n",
    "# 使用多版本整合数据\n",
    "consolidated_data = consolidate_source_data(df, fields_to_consolidate, versions_to_try)\n",
    "\n",
    "# 读目标（指定 sheet）\n",
    "wb = load_workbook(tgt_file)\n",
    "ws = wb[tgt_sheet]\n",
    "\n",
    "# 构建 ID→行号映射（不区分大小写）\n",
    "acc_number_to_rows = {}\n",
    "for row_num, row in enumerate(ws.iter_rows(min_row=2, min_col=1, max_col=2), start=2):\n",
    "    acc = str(row[0].value).strip().upper() if row[0].value is not None else None\n",
    "    if acc and acc != 'NONE':\n",
    "        acc_number_to_rows.setdefault(acc, []).append(row_num)\n",
    "\n",
    "matched_names = [n for n in consolidated_data if n in acc_number_to_rows]\n",
    "total_matched_rows = sum(len(acc_number_to_rows[n]) for n in matched_names)\n",
    "print(f\"\\n匹配到 {len(matched_names)} 个ID，共 {total_matched_rows} 行待写入\")\n",
    "\n",
    "# 写入\n",
    "write_start = time.time()\n",
    "i = 0\n",
    "for name_idx, (name, data) in enumerate(consolidated_data.items()):\n",
    "    if name in acc_number_to_rows:\n",
    "        for row_num in acc_number_to_rows[name]:\n",
    "            i += 1\n",
    "            write_fields_to_row(ws, row_num, data, field_mapping)\n",
    "            if i % 100 == 0:\n",
    "                print_progress(i, total_matched_rows, write_start, \"写入\")\n",
    "\n",
    "if i > 0:\n",
    "    print_progress(i, total_matched_rows, write_start, \"写入\")\n",
    "\n",
    "# 保存\n",
    "print(\"\\n正在保存...\")\n",
    "wb.save(tgt_file)\n",
    "print(f\"保存完成！总耗时 {time.time() - start_time:.1f}秒\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "287fa0b2-ae1c-46b2-b2c3-6065ec701a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "程序开始执行\n",
      "==================================================\n",
      "开始整合源数据，共 144 行，使用版本: ['V05']...\n",
      "整合进度: 1/144 (0.7%)\n",
      "整合完成，共 72 组 (ID,SIDE)\n",
      "\n",
      "匹配到 1 组 (ID,SIDE)，共 1 行待写入\n",
      "写入进度: 1/1 (100.0%) - 已用: 0.0s, 剩余: 0.0s\n",
      "\n",
      "正在保存...\n",
      "保存完成！总耗时 0.4秒\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import time\n",
    "import re\n",
    "\n",
    "# ---------- 基础函数 ----------\n",
    "def load_excel(file_path, sheet_name=0):\n",
    "    return pd.read_excel(file_path, sheet_name=sheet_name, dtype=str)\n",
    "\n",
    "def write_fields_to_row(ws, row_num, data, field_mapping):\n",
    "    for field, col in field_mapping.items():\n",
    "        if field in data:\n",
    "            ws[f\"{col}{row_num}\"] = data[field]\n",
    "\n",
    "# 仅保留数字1或2\n",
    "SIDE_PATTERN = re.compile(r'[12]')\n",
    "def normalize_side(side: str) -> str:\n",
    "    m = SIDE_PATTERN.search(str(side).upper()) if side else None\n",
    "    return m.group(0) if m else ''\n",
    "\n",
    "def consolidate_source_data(df, fields_to_consolidate, versions):\n",
    "    \"\"\"\n",
    "    按 (ID, SIDE) 复合键聚合指定字段；SIDE仅保留1/2\n",
    "    \"\"\"\n",
    "    consolidated = {}\n",
    "    real_cols = {c.upper() for c in df.columns}\n",
    "\n",
    "    base_fields, fv_map = [], {}\n",
    "    for full_field in fields_to_consolidate:\n",
    "        for v in versions:\n",
    "            if full_field.startswith(v):\n",
    "                bf = full_field[len(v):]\n",
    "                base_fields.append(bf)\n",
    "                fv_map[bf] = full_field\n",
    "                break\n",
    "\n",
    "    total = len(df)\n",
    "    print(f\"开始整合源数据，共 {total} 行，使用版本: {versions}...\")\n",
    "    for idx, row in df.iterrows():\n",
    "        uid = str(row['ID']).strip().upper() if pd.notna(row['ID']) else None\n",
    "        side_raw = str(row['SIDE']).strip() if pd.notna(row['SIDE']) else ''\n",
    "        side = normalize_side(side_raw)\n",
    "        if not uid or not side:\n",
    "            continue\n",
    "\n",
    "        key = (uid, side)\n",
    "        if key not in consolidated:\n",
    "            consolidated[key] = {fv_map[bf]: set() for bf in base_fields}\n",
    "\n",
    "        for bf in base_fields:\n",
    "            full_field = fv_map[bf]\n",
    "            for v in versions:\n",
    "                chk = v + bf\n",
    "                if chk.upper() in real_cols:\n",
    "                    val = row.get(chk)\n",
    "                    if pd.notna(val) and str(val).strip():\n",
    "                        consolidated[key][full_field].add(str(val).strip())\n",
    "                        break\n",
    "\n",
    "        if idx % 1000 == 0:\n",
    "            print(f\"整合进度: {idx+1}/{total} ({(idx+1)/total*100:.1f}%)\")\n",
    "\n",
    "    for k, data in consolidated.items():\n",
    "        for f in data:\n",
    "            consolidated[k][f] = \"; \".join(data[f]) if data[f] else \"\"\n",
    "    print(f\"整合完成，共 {len(consolidated)} 组 (ID,SIDE)\")\n",
    "    return consolidated\n",
    "\n",
    "def print_progress(current, total, start_time, operation=\"处理\"):\n",
    "    elapsed = time.time() - start_time\n",
    "    progress = (current / total) * 100\n",
    "    remaining = elapsed * total / current - elapsed if current else 0\n",
    "    print(f\"{operation}进度: {current}/{total} ({progress:.1f}%) - 已用: {elapsed:.1f}s, 剩余: {remaining:.1f}s\")\n",
    "\n",
    "# ---------- 字段清单（保持原样） ----------\n",
    "versions_to_try = [\"V05\"]\n",
    "field_list = [\n",
    "    f\"{versions_to_try[0]}CFWDTH\",\n",
    "    f\"{versions_to_try[0]}MCMJSW\",\n",
    "    f\"{versions_to_try[0]}JSW175\",\n",
    "    f\"{versions_to_try[0]}JSW200\",\n",
    "    f\"{versions_to_try[0]}JSW250\",\n",
    "    f\"{versions_to_try[0]}BARCDJD\",\n",
    "    f\"{versions_to_try[0]}JSW300\",\n",
    "    f\"{versions_to_try[0]}JSW225\",\n",
    "    f\"{versions_to_try[0]}TPCFDS\",\n",
    "    f\"{versions_to_try[0]}BMANG\",\n",
    "    f\"{versions_to_try[0]}JSW150\",\n",
    "    f\"{versions_to_try[0]}JSW275\",\n",
    "    f\"{versions_to_try[0]}LJSW850\",\n",
    "    f\"{versions_to_try[0]}LJSW900\",\n",
    "    f\"{versions_to_try[0]}LJSW700\",\n",
    "    f\"{versions_to_try[0]}LJSW825\",\n",
    "    f\"{versions_to_try[0]}LJSW750\",\n",
    "    f\"{versions_to_try[0]}LJSW875\",\n",
    "    f\"{versions_to_try[0]}LJSW725\",\n",
    "    f\"{versions_to_try[0]}LJSW775\",\n",
    "    f\"{versions_to_try[0]}LJSW800\",\n",
    "    f\"{versions_to_try[0]}XMJSW\"\n",
    "]\n",
    "\n",
    "def col_letter(n):\n",
    "    letter = \"\"\n",
    "    while n:\n",
    "        n, rem = divmod(n - 1, 26)\n",
    "        letter = chr(65 + rem) + letter\n",
    "    return letter\n",
    "\n",
    "field_mapping = {f.upper(): col_letter(i + 8) for i, f in enumerate(field_list)}\n",
    "fields_to_consolidate = list(field_mapping.keys())\n",
    "\n",
    "# ---------- 路径（保持原样） ----------\n",
    "src_file = r\"C:\\Users\\DXW\\OAI data\\OAIdatabase\\X-ray Quant\\kxr_qjsw_rel_duryea05.xlsx\"\n",
    "tgt_file = r\"C:\\Users\\DXW\\Desktop\\半月板手术_信息.xlsx\"\n",
    "tgt_sheet = '24m'\n",
    "\n",
    "# ---------- 主流程 ----------\n",
    "start_time = time.time()\n",
    "print(\"=\" * 50)\n",
    "print(\"程序开始执行\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "df = load_excel(src_file)\n",
    "df.columns = df.columns.str.strip().str.upper()\n",
    "\n",
    "consolidated_data = consolidate_source_data(df, fields_to_consolidate, versions_to_try)\n",
    "\n",
    "wb = load_workbook(tgt_file)\n",
    "ws = wb[tgt_sheet]\n",
    "\n",
    "# 目标表 SIDE 已是严格 1/2，直接按原值建索引\n",
    "key_to_rows = {}\n",
    "for row_num, row in enumerate(ws.iter_rows(min_row=2, min_col=1, max_col=3), start=2):\n",
    "    uid = str(row[0].value).strip().upper() if row[0].value else None\n",
    "    side = str(row[1].value).strip() if row[1].value else ''\n",
    "    if uid and side in {'1', '2'}:\n",
    "        key_to_rows.setdefault((uid, side), []).append(row_num)\n",
    "\n",
    "matched_keys = [k for k in consolidated_data if k in key_to_rows]\n",
    "total_rows = sum(len(key_to_rows[k]) for k in matched_keys)\n",
    "print(f\"\\n匹配到 {len(matched_keys)} 组 (ID,SIDE)，共 {total_rows} 行待写入\")\n",
    "\n",
    "write_start = time.time()\n",
    "i = 0\n",
    "for key, data in consolidated_data.items():\n",
    "    if key in key_to_rows:\n",
    "        for row_num in key_to_rows[key]:\n",
    "            i += 1\n",
    "            write_fields_to_row(ws, row_num, data, field_mapping)\n",
    "            if i % 100 == 0:\n",
    "                print_progress(i, total_rows, write_start, \"写入\")\n",
    "if i > 0:\n",
    "    print_progress(i, total_rows, write_start, \"写入\")\n",
    "\n",
    "print(\"\\n正在保存...\")\n",
    "wb.save(tgt_file)\n",
    "print(f\"保存完成！总耗时 {time.time() - start_time:.1f}秒\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b748d49-02a4-456e-be38-fccdb4dffab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dicom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
